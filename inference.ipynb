{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "from pytorch_faster_rcnn.datasets import ObjectDetectionDatasetSingle, ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn.faster_RCNN import get_faster_rcnn_resnet\n",
    "from pytorch_faster_rcnn.transformations import ComposeDouble\n",
    "from pytorch_faster_rcnn.transformations import ComposeSingle\n",
    "from pytorch_faster_rcnn.transformations import FunctionWrapperDouble\n",
    "from pytorch_faster_rcnn.transformations import FunctionWrapperSingle\n",
    "from pytorch_faster_rcnn.transformations import apply_nms, apply_score_threshold\n",
    "from pytorch_faster_rcnn.transformations import normalize_01\n",
    "from pytorch_faster_rcnn.utils import get_filenames_of_path, collate_single, save_json\n",
    "from pytorch_faster_rcnn.visual import DatasetViewer\n",
    "from pytorch_faster_rcnn.visual import DatasetViewerSingle\n",
    "from pytorch_faster_rcnn.backbone_resnet import ResNetBackbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate parameters for inference\n",
    "params = {'INPUT_DIR': 'pytorch_faster_rcnn/data/shelves/test',  # input files for which to generate prediction\n",
    "          'PREDICTIONS_PATH': 'pytorch_faster_rcnn/data/shelves/predictions',  #predictions save directory\n",
    "          'MODEL_DIR': 'experiment1',  #directory to load trained models from\n",
    "          'VERSION': 'version_6', #specific version to use for inference\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load input files for inference/prediction (unlabeled grocery images)\n",
    "inputs = get_filenames_of_path(pathlib.Path(params['INPUT_DIR']))\n",
    "inputs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations to apply to input data\n",
    "transforms = ComposeSingle([\n",
    "    FunctionWrapperSingle(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperSingle(normalize_01)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset (single because it has no targets)\n",
    "dataset = ObjectDetectionDatasetSingle(inputs=inputs,\n",
    "                                       transform=transforms,\n",
    "                                       use_cache=False,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "dataloader_prediction = DataLoader(dataset=dataset,\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=0,\n",
    "                                   collate_fn=collate_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model from version indicated in params\n",
    "checkpoint_path = str(os.getcwd()) +\"/\" + params['MODEL_DIR'] + \"/\" + params['VERSION'] + \"/checkpoints\"\n",
    "for file in os.listdir(checkpoint_path):\n",
    "    checkpoint_path += str(\"/\" + os.fsdecode(file))\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "model_state_dict = checkpoint['hyper_parameters']['model'].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate model with same parameters as version indicated in params (same backbone, anchor sizes, aspect_ratios, etc.)\n",
    "model = get_faster_rcnn_resnet(num_classes=2,\n",
    "                               backbone_name= ResNetBackbones.RESNET50,  \n",
    "                               anchor_size=((128, 256, 512),),\n",
    "                               aspect_ratios=((0.5, 1.0, 2.0),),\n",
    "                               fpn=False,\n",
    "                               min_size=1024,\n",
    "                               max_size=1025\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FasterRCNN:\n\tUnexpected key(s) in state_dict: \"backbone.5.4.conv1.weight\", \"backbone.5.4.bn1.weight\", \"backbone.5.4.bn1.bias\", \"backbone.5.4.bn1.running_mean\", \"backbone.5.4.bn1.running_var\", \"backbone.5.4.bn1.num_batches_tracked\", \"backbone.5.4.conv2.weight\", \"backbone.5.4.bn2.weight\", \"backbone.5.4.bn2.bias\", \"backbone.5.4.bn2.running_mean\", \"backbone.5.4.bn2.running_var\", \"backbone.5.4.bn2.num_batches_tracked\", \"backbone.5.4.conv3.weight\", \"backbone.5.4.bn3.weight\", \"backbone.5.4.bn3.bias\", \"backbone.5.4.bn3.running_mean\", \"backbone.5.4.bn3.running_var\", \"backbone.5.4.bn3.num_batches_tracked\", \"backbone.5.5.conv1.weight\", \"backbone.5.5.bn1.weight\", \"backbone.5.5.bn1.bias\", \"backbone.5.5.bn1.running_mean\", \"backbone.5.5.bn1.running_var\", \"backbone.5.5.bn1.num_batches_tracked\", \"backbone.5.5.conv2.weight\", \"backbone.5.5.bn2.weight\", \"backbone.5.5.bn2.bias\", \"backbone.5.5.bn2.running_mean\", \"backbone.5.5.bn2.running_var\", \"backbone.5.5.bn2.num_batches_tracked\", \"backbone.5.5.conv3.weight\", \"backbone.5.5.bn3.weight\", \"backbone.5.5.bn3.bias\", \"backbone.5.5.bn3.running_mean\", \"backbone.5.5.bn3.running_var\", \"backbone.5.5.bn3.num_batches_tracked\", \"backbone.5.6.conv1.weight\", \"backbone.5.6.bn1.weight\", \"backbone.5.6.bn1.bias\", \"backbone.5.6.bn1.running_mean\", \"backbone.5.6.bn1.running_var\", \"backbone.5.6.bn1.num_batches_tracked\", \"backbone.5.6.conv2.weight\", \"backbone.5.6.bn2.weight\", \"backbone.5.6.bn2.bias\", \"backbone.5.6.bn2.running_mean\", \"backbone.5.6.bn2.running_var\", \"backbone.5.6.bn2.num_batches_tracked\", \"backbone.5.6.conv3.weight\", \"backbone.5.6.bn3.weight\", \"backbone.5.6.bn3.bias\", \"backbone.5.6.bn3.running_mean\", \"backbone.5.6.bn3.running_var\", \"backbone.5.6.bn3.num_batches_tracked\", \"backbone.5.7.conv1.weight\", \"backbone.5.7.bn1.weight\", \"backbone.5.7.bn1.bias\", \"backbone.5.7.bn1.running_mean\", \"backbone.5.7.bn1.running_var\", \"backbone.5.7.bn1.num_batches_tracked\", \"backbone.5.7.conv2.weight\", \"backbone.5.7.bn2.weight\", \"backbone.5.7.bn2.bias\", \"backbone.5.7.bn2.running_mean\", \"backbone.5.7.bn2.running_var\", \"backbone.5.7.bn2.num_batches_tracked\", \"backbone.5.7.conv3.weight\", \"backbone.5.7.bn3.weight\", \"backbone.5.7.bn3.bias\", \"backbone.5.7.bn3.running_mean\", \"backbone.5.7.bn3.running_var\", \"backbone.5.7.bn3.num_batches_tracked\", \"backbone.6.6.conv1.weight\", \"backbone.6.6.bn1.weight\", \"backbone.6.6.bn1.bias\", \"backbone.6.6.bn1.running_mean\", \"backbone.6.6.bn1.running_var\", \"backbone.6.6.bn1.num_batches_tracked\", \"backbone.6.6.conv2.weight\", \"backbone.6.6.bn2.weight\", \"backbone.6.6.bn2.bias\", \"backbone.6.6.bn2.running_mean\", \"backbone.6.6.bn2.running_var\", \"backbone.6.6.bn2.num_batches_tracked\", \"backbone.6.6.conv3.weight\", \"backbone.6.6.bn3.weight\", \"backbone.6.6.bn3.bias\", \"backbone.6.6.bn3.running_mean\", \"backbone.6.6.bn3.running_var\", \"backbone.6.6.bn3.num_batches_tracked\", \"backbone.6.7.conv1.weight\", \"backbone.6.7.bn1.weight\", \"backbone.6.7.bn1.bias\", \"backbone.6.7.bn1.running_mean\", \"backbone.6.7.bn1.running_var\", \"backbone.6.7.bn1.num_batches_tracked\", \"backbone.6.7.conv2.weight\", \"backbone.6.7.bn2.weight\", \"backbone.6.7.bn2.bias\", \"backbone.6.7.bn2.running_mean\", \"backbone.6.7.bn2.running_var\", \"backbone.6.7.bn2.num_batches_tracked\", \"backbone.6.7.conv3.weight\", \"backbone.6.7.bn3.weight\", \"backbone.6.7.bn3.bias\", \"backbone.6.7.bn3.running_mean\", \"backbone.6.7.bn3.running_var\", \"backbone.6.7.bn3.num_batches_tracked\", \"backbone.6.8.conv1.weight\", \"backbone.6.8.bn1.weight\", \"backbone.6.8.bn1.bias\", \"backbone.6.8.bn1.running_mean\", \"backbone.6.8.bn1.running_var\", \"backbone.6.8.bn1.num_batches_tracked\", \"backbone.6.8.conv2.weight\", \"backbone.6.8.bn2.weight\", \"backbone.6.8.bn2.bias\", \"backbone.6.8.bn2.running_mean\", \"backbone.6.8.bn2.running_var\", \"backbone.6.8.bn2.num_batches_tracked\", \"backbone.6.8.conv3.weight\", \"backbone.6.8.bn3.weight\", \"backbone.6.8.bn3.bias\", \"backbone.6.8.bn3.running_mean\", \"backbone.6.8.bn3.running_var\", \"backbone.6.8.bn3.num_batches_tracked\", \"backbone.6.9.conv1.weight\", \"backbone.6.9.bn1.weight\", \"backbone.6.9.bn1.bias\", \"backbone.6.9.bn1.running_mean\", \"backbone.6.9.bn1.running_var\", \"backbone.6.9.bn1.num_batches_tracked\", \"backbone.6.9.conv2.weight\", \"backbone.6.9.bn2.weight\", \"backbone.6.9.bn2.bias\", \"backbone.6.9.bn2.running_mean\", \"backbone.6.9.bn2.running_var\", \"backbone.6.9.bn2.num_batches_tracked\", \"backbone.6.9.conv3.weight\", \"backbone.6.9.bn3.weight\", \"backbone.6.9.bn3.bias\", \"backbone.6.9.bn3.running_mean\", \"backbone.6.9.bn3.running_var\", \"backbone.6.9.bn3.num_batches_tracked\", \"backbone.6.10.conv1.weight\", \"backbone.6.10.bn1.weight\", \"backbone.6.10.bn1.bias\", \"backbone.6.10.bn1.running_mean\", \"backbone.6.10.bn1.running_var\", \"backbone.6.10.bn1.num_batches_tracked\", \"backbone.6.10.conv2.weight\", \"backbone.6.10.bn2.weight\", \"backbone.6.10.bn2.bias\", \"backbone.6.10.bn2.running_mean\", \"backbone.6.10.bn2.running_var\", \"backbone.6.10.bn2.num_batches_tracked\", \"backbone.6.10.conv3.weight\", \"backbone.6.10.bn3.weight\", \"backbone.6.10.bn3.bias\", \"backbone.6.10.bn3.running_mean\", \"backbone.6.10.bn3.running_var\", \"backbone.6.10.bn3.num_batches_tracked\", \"backbone.6.11.conv1.weight\", \"backbone.6.11.bn1.weight\", \"backbone.6.11.bn1.bias\", \"backbone.6.11.bn1.running_mean\", \"backbone.6.11.bn1.running_var\", \"backbone.6.11.bn1.num_batches_tracked\", \"backbone.6.11.conv2.weight\", \"backbone.6.11.bn2.weight\", \"backbone.6.11.bn2.bias\", \"backbone.6.11.bn2.running_mean\", \"backbone.6.11.bn2.running_var\", \"backbone.6.11.bn2.num_batches_tracked\", \"backbone.6.11.conv3.weight\", \"backbone.6.11.bn3.weight\", \"backbone.6.11.bn3.bias\", \"backbone.6.11.bn3.running_mean\", \"backbone.6.11.bn3.running_var\", \"backbone.6.11.bn3.num_batches_tracked\", \"backbone.6.12.conv1.weight\", \"backbone.6.12.bn1.weight\", \"backbone.6.12.bn1.bias\", \"backbone.6.12.bn1.running_mean\", \"backbone.6.12.bn1.running_var\", \"backbone.6.12.bn1.num_batches_tracked\", \"backbone.6.12.conv2.weight\", \"backbone.6.12.bn2.weight\", \"backbone.6.12.bn2.bias\", \"backbone.6.12.bn2.running_mean\", \"backbone.6.12.bn2.running_var\", \"backbone.6.12.bn2.num_batches_tracked\", \"backbone.6.12.conv3.weight\", \"backbone.6.12.bn3.weight\", \"backbone.6.12.bn3.bias\", \"backbone.6.12.bn3.running_mean\", \"backbone.6.12.bn3.running_var\", \"backbone.6.12.bn3.num_batches_tracked\", \"backbone.6.13.conv1.weight\", \"backbone.6.13.bn1.weight\", \"backbone.6.13.bn1.bias\", \"backbone.6.13.bn1.running_mean\", \"backbone.6.13.bn1.running_var\", \"backbone.6.13.bn1.num_batches_tracked\", \"backbone.6.13.conv2.weight\", \"backbone.6.13.bn2.weight\", \"backbone.6.13.bn2.bias\", \"backbone.6.13.bn2.running_mean\", \"backbone.6.13.bn2.running_var\", \"backbone.6.13.bn2.num_batches_tracked\", \"backbone.6.13.conv3.weight\", \"backbone.6.13.bn3.weight\", \"backbone.6.13.bn3.bias\", \"backbone.6.13.bn3.running_mean\", \"backbone.6.13.bn3.running_var\", \"backbone.6.13.bn3.num_batches_tracked\", \"backbone.6.14.conv1.weight\", \"backbone.6.14.bn1.weight\", \"backbone.6.14.bn1.bias\", \"backbone.6.14.bn1.running_mean\", \"backbone.6.14.bn1.running_var\", \"backbone.6.14.bn1.num_batches_tracked\", \"backbone.6.14.conv2.weight\", \"backbone.6.14.bn2.weight\", \"backbone.6.14.bn2.bias\", \"backbone.6.14.bn2.running_mean\", \"backbone.6.14.bn2.running_var\", \"backbone.6.14.bn2.num_batches_tracked\", \"backbone.6.14.conv3.weight\", \"backbone.6.14.bn3.weight\", \"backbone.6.14.bn3.bias\", \"backbone.6.14.bn3.running_mean\", \"backbone.6.14.bn3.running_var\", \"backbone.6.14.bn3.num_batches_tracked\", \"backbone.6.15.conv1.weight\", \"backbone.6.15.bn1.weight\", \"backbone.6.15.bn1.bias\", \"backbone.6.15.bn1.running_mean\", \"backbone.6.15.bn1.running_var\", \"backbone.6.15.bn1.num_batches_tracked\", \"backbone.6.15.conv2.weight\", \"backbone.6.15.bn2.weight\", \"backbone.6.15.bn2.bias\", \"backbone.6.15.bn2.running_mean\", \"backbone.6.15.bn2.running_var\", \"backbone.6.15.bn2.num_batches_tracked\", \"backbone.6.15.conv3.weight\", \"backbone.6.15.bn3.weight\", \"backbone.6.15.bn3.bias\", \"backbone.6.15.bn3.running_mean\", \"backbone.6.15.bn3.running_var\", \"backbone.6.15.bn3.num_batches_tracked\", \"backbone.6.16.conv1.weight\", \"backbone.6.16.bn1.weight\", \"backbone.6.16.bn1.bias\", \"backbone.6.16.bn1.running_mean\", \"backbone.6.16.bn1.running_var\", \"backbone.6.16.bn1.num_batches_tracked\", \"backbone.6.16.conv2.weight\", \"backbone.6.16.bn2.weight\", \"backbone.6.16.bn2.bias\", \"backbone.6.16.bn2.running_mean\", \"backbone.6.16.bn2.running_var\", \"backbone.6.16.bn2.num_batches_tracked\", \"backbone.6.16.conv3.weight\", \"backbone.6.16.bn3.weight\", \"backbone.6.16.bn3.bias\", \"backbone.6.16.bn3.running_mean\", \"backbone.6.16.bn3.running_var\", \"backbone.6.16.bn3.num_batches_tracked\", \"backbone.6.17.conv1.weight\", \"backbone.6.17.bn1.weight\", \"backbone.6.17.bn1.bias\", \"backbone.6.17.bn1.running_mean\", \"backbone.6.17.bn1.running_var\", \"backbone.6.17.bn1.num_batches_tracked\", \"backbone.6.17.conv2.weight\", \"backbone.6.17.bn2.weight\", \"backbone.6.17.bn2.bias\", \"backbone.6.17.bn2.running_mean\", \"backbone.6.17.bn2.running_var\", \"backbone.6.17.bn2.num_batches_tracked\", \"backbone.6.17.conv3.weight\", \"backbone.6.17.bn3.weight\", \"backbone.6.17.bn3.bias\", \"backbone.6.17.bn3.running_mean\", \"backbone.6.17.bn3.running_var\", \"backbone.6.17.bn3.num_batches_tracked\", \"backbone.6.18.conv1.weight\", \"backbone.6.18.bn1.weight\", \"backbone.6.18.bn1.bias\", \"backbone.6.18.bn1.running_mean\", \"backbone.6.18.bn1.running_var\", \"backbone.6.18.bn1.num_batches_tracked\", \"backbone.6.18.conv2.weight\", \"backbone.6.18.bn2.weight\", \"backbone.6.18.bn2.bias\", \"backbone.6.18.bn2.running_mean\", \"backbone.6.18.bn2.running_var\", \"backbone.6.18.bn2.num_batches_tracked\", \"backbone.6.18.conv3.weight\", \"backbone.6.18.bn3.weight\", \"backbone.6.18.bn3.bias\", \"backbone.6.18.bn3.running_mean\", \"backbone.6.18.bn3.running_var\", \"backbone.6.18.bn3.num_batches_tracked\", \"backbone.6.19.conv1.weight\", \"backbone.6.19.bn1.weight\", \"backbone.6.19.bn1.bias\", \"backbone.6.19.bn1.running_mean\", \"backbone.6.19.bn1.running_var\", \"backbone.6.19.bn1.num_batches_tracked\", \"backbone.6.19.conv2.weight\", \"backbone.6.19.bn2.weight\", \"backbone.6.19.bn2.bias\", \"backbone.6.19.bn2.running_mean\", \"backbone.6.19.bn2.running_var\", \"backbone.6.19.bn2.num_batches_tracked\", \"backbone.6.19.conv3.weight\", \"backbone.6.19.bn3.weight\", \"backbone.6.19.bn3.bias\", \"backbone.6.19.bn3.running_mean\", \"backbone.6.19.bn3.running_var\", \"backbone.6.19.bn3.num_batches_tracked\", \"backbone.6.20.conv1.weight\", \"backbone.6.20.bn1.weight\", \"backbone.6.20.bn1.bias\", \"backbone.6.20.bn1.running_mean\", \"backbone.6.20.bn1.running_var\", \"backbone.6.20.bn1.num_batches_tracked\", \"backbone.6.20.conv2.weight\", \"backbone.6.20.bn2.weight\", \"backbone.6.20.bn2.bias\", \"backbone.6.20.bn2.running_mean\", \"backbone.6.20.bn2.running_var\", \"backbone.6.20.bn2.num_batches_tracked\", \"backbone.6.20.conv3.weight\", \"backbone.6.20.bn3.weight\", \"backbone.6.20.bn3.bias\", \"backbone.6.20.bn3.running_mean\", \"backbone.6.20.bn3.running_var\", \"backbone.6.20.bn3.num_batches_tracked\", \"backbone.6.21.conv1.weight\", \"backbone.6.21.bn1.weight\", \"backbone.6.21.bn1.bias\", \"backbone.6.21.bn1.running_mean\", \"backbone.6.21.bn1.running_var\", \"backbone.6.21.bn1.num_batches_tracked\", \"backbone.6.21.conv2.weight\", \"backbone.6.21.bn2.weight\", \"backbone.6.21.bn2.bias\", \"backbone.6.21.bn2.running_mean\", \"backbone.6.21.bn2.running_var\", \"backbone.6.21.bn2.num_batches_tracked\", \"backbone.6.21.conv3.weight\", \"backbone.6.21.bn3.weight\", \"backbone.6.21.bn3.bias\", \"backbone.6.21.bn3.running_mean\", \"backbone.6.21.bn3.running_var\", \"backbone.6.21.bn3.num_batches_tracked\", \"backbone.6.22.conv1.weight\", \"backbone.6.22.bn1.weight\", \"backbone.6.22.bn1.bias\", \"backbone.6.22.bn1.running_mean\", \"backbone.6.22.bn1.running_var\", \"backbone.6.22.bn1.num_batches_tracked\", \"backbone.6.22.conv2.weight\", \"backbone.6.22.bn2.weight\", \"backbone.6.22.bn2.bias\", \"backbone.6.22.bn2.running_mean\", \"backbone.6.22.bn2.running_var\", \"backbone.6.22.bn2.num_batches_tracked\", \"backbone.6.22.conv3.weight\", \"backbone.6.22.bn3.weight\", \"backbone.6.22.bn3.bias\", \"backbone.6.22.bn3.running_mean\", \"backbone.6.22.bn3.running_var\", \"backbone.6.22.bn3.num_batches_tracked\", \"backbone.6.23.conv1.weight\", \"backbone.6.23.bn1.weight\", \"backbone.6.23.bn1.bias\", \"backbone.6.23.bn1.running_mean\", \"backbone.6.23.bn1.running_var\", \"backbone.6.23.bn1.num_batches_tracked\", \"backbone.6.23.conv2.weight\", \"backbone.6.23.bn2.weight\", \"backbone.6.23.bn2.bias\", \"backbone.6.23.bn2.running_mean\", \"backbone.6.23.bn2.running_var\", \"backbone.6.23.bn2.num_batches_tracked\", \"backbone.6.23.conv3.weight\", \"backbone.6.23.bn3.weight\", \"backbone.6.23.bn3.bias\", \"backbone.6.23.bn3.running_mean\", \"backbone.6.23.bn3.running_var\", \"backbone.6.23.bn3.num_batches_tracked\", \"backbone.6.24.conv1.weight\", \"backbone.6.24.bn1.weight\", \"backbone.6.24.bn1.bias\", \"backbone.6.24.bn1.running_mean\", \"backbone.6.24.bn1.running_var\", \"backbone.6.24.bn1.num_batches_tracked\", \"backbone.6.24.conv2.weight\", \"backbone.6.24.bn2.weight\", \"backbone.6.24.bn2.bias\", \"backbone.6.24.bn2.running_mean\", \"backbone.6.24.bn2.running_var\", \"backbone.6.24.bn2.num_batches_tracked\", \"backbone.6.24.conv3.weight\", \"backbone.6.24.bn3.weight\", \"backbone.6.24.bn3.bias\", \"backbone.6.24.bn3.running_mean\", \"backbone.6.24.bn3.running_var\", \"backbone.6.24.bn3.num_batches_tracked\", \"backbone.6.25.conv1.weight\", \"backbone.6.25.bn1.weight\", \"backbone.6.25.bn1.bias\", \"backbone.6.25.bn1.running_mean\", \"backbone.6.25.bn1.running_var\", \"backbone.6.25.bn1.num_batches_tracked\", \"backbone.6.25.conv2.weight\", \"backbone.6.25.bn2.weight\", \"backbone.6.25.bn2.bias\", \"backbone.6.25.bn2.running_mean\", \"backbone.6.25.bn2.running_var\", \"backbone.6.25.bn2.num_batches_tracked\", \"backbone.6.25.conv3.weight\", \"backbone.6.25.bn3.weight\", \"backbone.6.25.bn3.bias\", \"backbone.6.25.bn3.running_mean\", \"backbone.6.25.bn3.running_var\", \"backbone.6.25.bn3.num_batches_tracked\", \"backbone.6.26.conv1.weight\", \"backbone.6.26.bn1.weight\", \"backbone.6.26.bn1.bias\", \"backbone.6.26.bn1.running_mean\", \"backbone.6.26.bn1.running_var\", \"backbone.6.26.bn1.num_batches_tracked\", \"backbone.6.26.conv2.weight\", \"backbone.6.26.bn2.weight\", \"backbone.6.26.bn2.bias\", \"backbone.6.26.bn2.running_mean\", \"backbone.6.26.bn2.running_var\", \"backbone.6.26.bn2.num_batches_tracked\", \"backbone.6.26.conv3.weight\", \"backbone.6.26.bn3.weight\", \"backbone.6.26.bn3.bias\", \"backbone.6.26.bn3.running_mean\", \"backbone.6.26.bn3.running_var\", \"backbone.6.26.bn3.num_batches_tracked\", \"backbone.6.27.conv1.weight\", \"backbone.6.27.bn1.weight\", \"backbone.6.27.bn1.bias\", \"backbone.6.27.bn1.running_mean\", \"backbone.6.27.bn1.running_var\", \"backbone.6.27.bn1.num_batches_tracked\", \"backbone.6.27.conv2.weight\", \"backbone.6.27.bn2.weight\", \"backbone.6.27.bn2.bias\", \"backbone.6.27.bn2.running_mean\", \"backbone.6.27.bn2.running_var\", \"backbone.6.27.bn2.num_batches_tracked\", \"backbone.6.27.conv3.weight\", \"backbone.6.27.bn3.weight\", \"backbone.6.27.bn3.bias\", \"backbone.6.27.bn3.running_mean\", \"backbone.6.27.bn3.running_var\", \"backbone.6.27.bn3.num_batches_tracked\", \"backbone.6.28.conv1.weight\", \"backbone.6.28.bn1.weight\", \"backbone.6.28.bn1.bias\", \"backbone.6.28.bn1.running_mean\", \"backbone.6.28.bn1.running_var\", \"backbone.6.28.bn1.num_batches_tracked\", \"backbone.6.28.conv2.weight\", \"backbone.6.28.bn2.weight\", \"backbone.6.28.bn2.bias\", \"backbone.6.28.bn2.running_mean\", \"backbone.6.28.bn2.running_var\", \"backbone.6.28.bn2.num_batches_tracked\", \"backbone.6.28.conv3.weight\", \"backbone.6.28.bn3.weight\", \"backbone.6.28.bn3.bias\", \"backbone.6.28.bn3.running_mean\", \"backbone.6.28.bn3.running_var\", \"backbone.6.28.bn3.num_batches_tracked\", \"backbone.6.29.conv1.weight\", \"backbone.6.29.bn1.weight\", \"backbone.6.29.bn1.bias\", \"backbone.6.29.bn1.running_mean\", \"backbone.6.29.bn1.running_var\", \"backbone.6.29.bn1.num_batches_tracked\", \"backbone.6.29.conv2.weight\", \"backbone.6.29.bn2.weight\", \"backbone.6.29.bn2.bias\", \"backbone.6.29.bn2.running_mean\", \"backbone.6.29.bn2.running_var\", \"backbone.6.29.bn2.num_batches_tracked\", \"backbone.6.29.conv3.weight\", \"backbone.6.29.bn3.weight\", \"backbone.6.29.bn3.bias\", \"backbone.6.29.bn3.running_mean\", \"backbone.6.29.bn3.running_var\", \"backbone.6.29.bn3.num_batches_tracked\", \"backbone.6.30.conv1.weight\", \"backbone.6.30.bn1.weight\", \"backbone.6.30.bn1.bias\", \"backbone.6.30.bn1.running_mean\", \"backbone.6.30.bn1.running_var\", \"backbone.6.30.bn1.num_batches_tracked\", \"backbone.6.30.conv2.weight\", \"backbone.6.30.bn2.weight\", \"backbone.6.30.bn2.bias\", \"backbone.6.30.bn2.running_mean\", \"backbone.6.30.bn2.running_var\", \"backbone.6.30.bn2.num_batches_tracked\", \"backbone.6.30.conv3.weight\", \"backbone.6.30.bn3.weight\", \"backbone.6.30.bn3.bias\", \"backbone.6.30.bn3.running_mean\", \"backbone.6.30.bn3.running_var\", \"backbone.6.30.bn3.num_batches_tracked\", \"backbone.6.31.conv1.weight\", \"backbone.6.31.bn1.weight\", \"backbone.6.31.bn1.bias\", \"backbone.6.31.bn1.running_mean\", \"backbone.6.31.bn1.running_var\", \"backbone.6.31.bn1.num_batches_tracked\", \"backbone.6.31.conv2.weight\", \"backbone.6.31.bn2.weight\", \"backbone.6.31.bn2.bias\", \"backbone.6.31.bn2.running_mean\", \"backbone.6.31.bn2.running_var\", \"backbone.6.31.bn2.num_batches_tracked\", \"backbone.6.31.conv3.weight\", \"backbone.6.31.bn3.weight\", \"backbone.6.31.bn3.bias\", \"backbone.6.31.bn3.running_mean\", \"backbone.6.31.bn3.running_var\", \"backbone.6.31.bn3.num_batches_tracked\", \"backbone.6.32.conv1.weight\", \"backbone.6.32.bn1.weight\", \"backbone.6.32.bn1.bias\", \"backbone.6.32.bn1.running_mean\", \"backbone.6.32.bn1.running_var\", \"backbone.6.32.bn1.num_batches_tracked\", \"backbone.6.32.conv2.weight\", \"backbone.6.32.bn2.weight\", \"backbone.6.32.bn2.bias\", \"backbone.6.32.bn2.running_mean\", \"backbone.6.32.bn2.running_var\", \"backbone.6.32.bn2.num_batches_tracked\", \"backbone.6.32.conv3.weight\", \"backbone.6.32.bn3.weight\", \"backbone.6.32.bn3.bias\", \"backbone.6.32.bn3.running_mean\", \"backbone.6.32.bn3.running_var\", \"backbone.6.32.bn3.num_batches_tracked\", \"backbone.6.33.conv1.weight\", \"backbone.6.33.bn1.weight\", \"backbone.6.33.bn1.bias\", \"backbone.6.33.bn1.running_mean\", \"backbone.6.33.bn1.running_var\", \"backbone.6.33.bn1.num_batches_tracked\", \"backbone.6.33.conv2.weight\", \"backbone.6.33.bn2.weight\", \"backbone.6.33.bn2.bias\", \"backbone.6.33.bn2.running_mean\", \"backbone.6.33.bn2.running_var\", \"backbone.6.33.bn2.num_batches_tracked\", \"backbone.6.33.conv3.weight\", \"backbone.6.33.bn3.weight\", \"backbone.6.33.bn3.bias\", \"backbone.6.33.bn3.running_mean\", \"backbone.6.33.bn3.running_var\", \"backbone.6.33.bn3.num_batches_tracked\", \"backbone.6.34.conv1.weight\", \"backbone.6.34.bn1.weight\", \"backbone.6.34.bn1.bias\", \"backbone.6.34.bn1.running_mean\", \"backbone.6.34.bn1.running_var\", \"backbone.6.34.bn1.num_batches_tracked\", \"backbone.6.34.conv2.weight\", \"backbone.6.34.bn2.weight\", \"backbone.6.34.bn2.bias\", \"backbone.6.34.bn2.running_mean\", \"backbone.6.34.bn2.running_var\", \"backbone.6.34.bn2.num_batches_tracked\", \"backbone.6.34.conv3.weight\", \"backbone.6.34.bn3.weight\", \"backbone.6.34.bn3.bias\", \"backbone.6.34.bn3.running_mean\", \"backbone.6.34.bn3.running_var\", \"backbone.6.34.bn3.num_batches_tracked\", \"backbone.6.35.conv1.weight\", \"backbone.6.35.bn1.weight\", \"backbone.6.35.bn1.bias\", \"backbone.6.35.bn1.running_mean\", \"backbone.6.35.bn1.running_var\", \"backbone.6.35.bn1.num_batches_tracked\", \"backbone.6.35.conv2.weight\", \"backbone.6.35.bn2.weight\", \"backbone.6.35.bn2.bias\", \"backbone.6.35.bn2.running_mean\", \"backbone.6.35.bn2.running_var\", \"backbone.6.35.bn2.num_batches_tracked\", \"backbone.6.35.conv3.weight\", \"backbone.6.35.bn3.weight\", \"backbone.6.35.bn3.bias\", \"backbone.6.35.bn3.running_mean\", \"backbone.6.35.bn3.running_var\", \"backbone.6.35.bn3.num_batches_tracked\". \n\tsize mismatch for rpn.head.cls_logits.weight: copying a param with shape torch.Size([15, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([9, 2048, 1, 1]).\n\tsize mismatch for rpn.head.cls_logits.bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([9]).\n\tsize mismatch for rpn.head.bbox_pred.weight: copying a param with shape torch.Size([60, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([36, 2048, 1, 1]).\n\tsize mismatch for rpn.head.bbox_pred.bias: copying a param with shape torch.Size([60]) from checkpoint, the shape in current model is torch.Size([36]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/wandermarijnissen/repos/code_final_version/inference.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wandermarijnissen/repos/code_final_version/inference.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#load weights onto model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wandermarijnissen/repos/code_final_version/inference.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(model_state_dict)\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1478\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1479\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1481\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1483\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1484\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FasterRCNN:\n\tUnexpected key(s) in state_dict: \"backbone.5.4.conv1.weight\", \"backbone.5.4.bn1.weight\", \"backbone.5.4.bn1.bias\", \"backbone.5.4.bn1.running_mean\", \"backbone.5.4.bn1.running_var\", \"backbone.5.4.bn1.num_batches_tracked\", \"backbone.5.4.conv2.weight\", \"backbone.5.4.bn2.weight\", \"backbone.5.4.bn2.bias\", \"backbone.5.4.bn2.running_mean\", \"backbone.5.4.bn2.running_var\", \"backbone.5.4.bn2.num_batches_tracked\", \"backbone.5.4.conv3.weight\", \"backbone.5.4.bn3.weight\", \"backbone.5.4.bn3.bias\", \"backbone.5.4.bn3.running_mean\", \"backbone.5.4.bn3.running_var\", \"backbone.5.4.bn3.num_batches_tracked\", \"backbone.5.5.conv1.weight\", \"backbone.5.5.bn1.weight\", \"backbone.5.5.bn1.bias\", \"backbone.5.5.bn1.running_mean\", \"backbone.5.5.bn1.running_var\", \"backbone.5.5.bn1.num_batches_tracked\", \"backbone.5.5.conv2.weight\", \"backbone.5.5.bn2.weight\", \"backbone.5.5.bn2.bias\", \"backbone.5.5.bn2.running_mean\", \"backbone.5.5.bn2.running_var\", \"backbone.5.5.bn2.num_batches_tracked\", \"backbone.5.5.conv3.weight\", \"backbone.5.5.bn3.weight\", \"backbone.5.5.bn3.bias\", \"backbone.5.5.bn3.running_mean\", \"backbone.5.5.bn3.running_var\", \"backbone.5.5.bn3.num_batches_tracked\", \"backbone.5.6.conv1.weight\", \"backbone.5.6.bn1.weight\", \"backbone.5.6.bn1.bias\", \"backbone.5.6.bn1.running_mean\", \"backbone.5.6.bn1.running_var\", \"backbone.5.6.bn1.num_batches_tracked\", \"backbone.5.6.conv2.weight\", \"backbone.5.6.bn2.weight\", \"backbone.5.6.bn2.bias\", \"backbone.5.6.bn2.running_mean\", \"backbone.5.6.bn2.running_var\", \"backbone.5.6.bn2.num_batches_tracked\", \"backbone.5.6.conv3.weight\", \"backbone.5.6.bn3.weight\", \"backbone.5.6.bn3.bias\", \"backbone.5.6.bn3.running_mean\", \"backbone.5.6.bn3.running_var\", \"backbone.5.6.bn3.num_batches_tracked\", \"backbone.5.7.conv1.weight\", \"backbone.5.7.bn1.weight\", \"backbone.5.7.bn1.bias\", \"backbone.5.7.bn1.running_mean\", \"backbone.5.7.bn1.running_var\", \"backbone.5.7.bn1.num_batches_tracked\", \"backbone.5.7.conv2.weight\", \"backbone.5.7.bn2.weight\", \"backbone.5.7.bn2.bias\", \"backbone.5.7.bn2.running_mean\", \"backbone.5.7.bn2.running_var\", \"backbone.5.7.bn2.num_batches_tracked\", \"backbone.5.7.conv3.weight\", \"backbone.5.7.bn3.weight\", \"backbone.5.7.bn3.bias\", \"backbone.5.7.bn3.running_mean\", \"backbone.5.7.bn3.running_var\", \"backbone.5.7.bn3.num_batches_tracked\", \"backbone.6.6.conv1.weight\", \"backbone.6.6.bn1.weight\", \"backbone.6.6.bn1.bias\", \"backbone.6.6.bn1.running_mean\", \"backbone.6.6.bn1.running_var\", \"backbone.6.6.bn1.num_batches_tracked\", \"backbone.6.6.conv2.weight\", \"backbone.6.6.bn2.weight\", \"backbone.6.6.bn2.bias\", \"backbone.6.6.bn2.running_mean\", \"backbone.6.6.bn2.running_var\", \"backbone.6.6.bn2.num_batches_tracked\", \"backbone.6.6.conv3.weight\", \"backbone.6.6.bn3.weight\", \"backbone.6.6.bn3.bias\", \"backbone.6.6.bn3.running_mean\", \"backbone.6.6.bn3.running_var\", \"backbone.6.6.bn3.num_batches_tracked\", \"backbone.6.7.conv1.weight\", \"backbone.6.7.bn1.weight\", \"backbone.6.7.bn1.bias\", \"backbone.6.7.bn1.running_mean\", \"backbone.6.7.bn1.running_var\", \"backbone.6.7.bn1.num_batches_tracked\", \"backbone.6.7.conv2.weight\", \"backbone.6.7.bn2.weight\", \"backbone.6.7.bn2.bias\", \"backbone.6.7.bn2.running_mean\", \"backbone.6.7.bn2.running_var\", \"backbone.6.7.bn2.num_batches_tracked\", \"backbone.6.7.conv3.weight\", \"backbone.6.7.bn3.weight\", \"backbone.6.7.bn3.bias\", \"backbone.6.7.bn3.running_mean\", \"backbone.6.7.bn3.running_var\", \"backbone.6.7.bn3.num_batches_tracked\", \"backbone.6.8.conv1.weight\", \"backbone.6.8.bn1.weight\", \"backbone.6.8.bn1.bias\", \"backbone.6.8.bn1.running_mean\", \"backbone.6.8.bn1.running_var\", \"backbone.6.8.bn1.num_batches_tracked\", \"backbone.6.8.conv2.weight\", \"backbone.6.8.bn2.weight\", \"backbone.6.8.bn2.bias\", \"backbone.6.8.bn2.running_mean\", \"backbone.6.8.bn2.running_var\", \"backbone.6.8.bn2.num_batches_tracked\", \"backbone.6.8.conv3.weight\", \"backbone.6.8.bn3.weight\", \"backbone.6.8.bn3.bias\", \"backbone.6.8.bn3.running_mean\", \"backbone.6.8.bn3.running_var\", \"backbone.6.8.bn3.num_batches_tracked\", \"backbone.6.9.conv1.weight\", \"backbone.6.9.bn1.weight\", \"backbone.6.9.bn1.bias\", \"backbone.6.9.bn1.running_mean\", \"backbone.6.9.bn1.running_var\", \"backbone.6.9.bn1.num_batches_tracked\", \"backbone.6.9.conv2.weight\", \"backbone.6.9.bn2.weight\", \"backbone.6.9.bn2.bias\", \"backbone.6.9.bn2.running_mean\", \"backbone.6.9.bn2.running_var\", \"backbone.6.9.bn2.num_batches_tracked\", \"backbone.6.9.conv3.weight\", \"backbone.6.9.bn3.weight\", \"backbone.6.9.bn3.bias\", \"backbone.6.9.bn3.running_mean\", \"backbone.6.9.bn3.running_var\", \"backbone.6.9.bn3.num_batches_tracked\", \"backbone.6.10.conv1.weight\", \"backbone.6.10.bn1.weight\", \"backbone.6.10.bn1.bias\", \"backbone.6.10.bn1.running_mean\", \"backbone.6.10.bn1.running_var\", \"backbone.6.10.bn1.num_batches_tracked\", \"backbone.6.10.conv2.weight\", \"backbone.6.10.bn2.weight\", \"backbone.6.10.bn2.bias\", \"backbone.6.10.bn2.running_mean\", \"backbone.6.10.bn2.running_var\", \"backbone.6.10.bn2.num_batches_tracked\", \"backbone.6.10.conv3.weight\", \"backbone.6.10.bn3.weight\", \"backbone.6.10.bn3.bias\", \"backbone.6.10.bn3.running_mean\", \"backbone.6.10.bn3.running_var\", \"backbone.6.10.bn3.num_batches_tracked\", \"backbone.6.11.conv1.weight\", \"backbone.6.11.bn1.weight\", \"backbone.6.11.bn1.bias\", \"backbone.6.11.bn1.running_mean\", \"backbone.6.11.bn1.running_var\", \"backbone.6.11.bn1.num_batches_tracked\", \"backbone.6.11.conv2.weight\", \"backbone.6.11.bn2.weight\", \"backbone.6.11.bn2.bias\", \"backbone.6.11.bn2.running_mean\", \"backbone.6.11.bn2.running_var\", \"backbone.6.11.bn2.num_batches_tracked\", \"backbone.6.11.conv3.weight\", \"backbone.6.11.bn3.weight\", \"backbone.6.11.bn3.bias\", \"backbone.6.11.bn3.running_mean\", \"backbone.6.11.bn3.running_var\", \"backbone.6.11.bn3.num_batches_tracked\", \"backbone.6.12.conv1.weight\", \"backbone.6.12.bn1.weight\", \"backbone.6.12.bn1.bias\", \"backbone.6.12.bn1.running_mean\", \"backbone.6.12.bn1.running_var\", \"backbone.6.12.bn1.num_batches_tracked\", \"backbone.6.12.conv2.weight\", \"backbone.6.12.bn2.weight\", \"backbone.6.12.bn2.bias\", \"backbone.6.12.bn2.running_mean\", \"backbone.6.12.bn2.running_var\", \"backbone.6.12.bn2.num_batches_tracked\", \"backbone.6.12.conv3.weight\", \"backbone.6.12.bn3.weight\", \"backbone.6.12.bn3.bias\", \"backbone.6.12.bn3.running_mean\", \"backbone.6.12.bn3.running_var\", \"backbone.6.12.bn3.num_batches_tracked\", \"backbone.6.13.conv1.weight\", \"backbone.6.13.bn1.weight\", \"backbone.6.13.bn1.bias\", \"backbone.6.13.bn1.running_mean\", \"backbone.6.13.bn1.running_var\", \"backbone.6.13.bn1.num_batches_tracked\", \"backbone.6.13.conv2.weight\", \"backbone.6.13.bn2.weight\", \"backbone.6.13.bn2.bias\", \"backbone.6.13.bn2.running_mean\", \"backbone.6.13.bn2.running_var\", \"backbone.6.13.bn2.num_batches_tracked\", \"backbone.6.13.conv3.weight\", \"backbone.6.13.bn3.weight\", \"backbone.6.13.bn3.bias\", \"backbone.6.13.bn3.running_mean\", \"backbone.6.13.bn3.running_var\", \"backbone.6.13.bn3.num_batches_tracked\", \"backbone.6.14.conv1.weight\", \"backbone.6.14.bn1.weight\", \"backbone.6.14.bn1.bias\", \"backbone.6.14.bn1.running_mean\", \"backbone.6.14.bn1.running_var\", \"backbone.6.14.bn1.num_batches_tracked\", \"backbone.6.14.conv2.weight\", \"backbone.6.14.bn2.weight\", \"backbone.6.14.bn2.bias\", \"backbone.6.14.bn2.running_mean\", \"backbone.6.14.bn2.running_var\", \"backbone.6.14.bn2.num_batches_tracked\", \"backbone.6.14.conv3.weight\", \"backbone.6.14.bn3.weight\", \"backbone.6.14.bn3.bias\", \"backbone.6.14.bn3.running_mean\", \"backbone.6.14.bn3.running_var\", \"backbone.6.14.bn3.num_batches_tracked\", \"backbone.6.15.conv1.weight\", \"backbone.6.15.bn1.weight\", \"backbone.6.15.bn1.bias\", \"backbone.6.15.bn1.running_mean\", \"backbone.6.15.bn1.running_var\", \"backbone.6.15.bn1.num_batches_tracked\", \"backbone.6.15.conv2.weight\", \"backbone.6.15.bn2.weight\", \"backbone.6.15.bn2.bias\", \"backbone.6.15.bn2.running_mean\", \"backbone.6.15.bn2.running_var\", \"backbone.6.15.bn2.num_batches_tracked\", \"backbone.6.15.conv3.weight\", \"backbone.6.15.bn3.weight\", \"backbone.6.15.bn3.bias\", \"backbone.6.15.bn3.running_mean\", \"backbone.6.15.bn3.running_var\", \"backbone.6.15.bn3.num_batches_tracked\", \"backbone.6.16.conv1.weight\", \"backbone.6.16.bn1.weight\", \"backbone.6.16.bn1.bias\", \"backbone.6.16.bn1.running_mean\", \"backbone.6.16.bn1.running_var\", \"backbone.6.16.bn1.num_batches_tracked\", \"backbone.6.16.conv2.weight\", \"backbone.6.16.bn2.weight\", \"backbone.6.16.bn2.bias\", \"backbone.6.16.bn2.running_mean\", \"backbone.6.16.bn2.running_var\", \"backbone.6.16.bn2.num_batches_tracked\", \"backbone.6.16.conv3.weight\", \"backbone.6.16.bn3.weight\", \"backbone.6.16.bn3.bias\", \"backbone.6.16.bn3.running_mean\", \"backbone.6.16.bn3.running_var\", \"backbone.6.16.bn3.num_batches_tracked\", \"backbone.6.17.conv1.weight\", \"backbone.6.17.bn1.weight\", \"backbone.6.17.bn1.bias\", \"backbone.6.17.bn1.running_mean\", \"backbone.6.17.bn1.running_var\", \"backbone.6.17.bn1.num_batches_tracked\", \"backbone.6.17.conv2.weight\", \"backbone.6.17.bn2.weight\", \"backbone.6.17.bn2.bias\", \"backbone.6.17.bn2.running_mean\", \"backbone.6.17.bn2.running_var\", \"backbone.6.17.bn2.num_batches_tracked\", \"backbone.6.17.conv3.weight\", \"backbone.6.17.bn3.weight\", \"backbone.6.17.bn3.bias\", \"backbone.6.17.bn3.running_mean\", \"backbone.6.17.bn3.running_var\", \"backbone.6.17.bn3.num_batches_tracked\", \"backbone.6.18.conv1.weight\", \"backbone.6.18.bn1.weight\", \"backbone.6.18.bn1.bias\", \"backbone.6.18.bn1.running_mean\", \"backbone.6.18.bn1.running_var\", \"backbone.6.18.bn1.num_batches_tracked\", \"backbone.6.18.conv2.weight\", \"backbone.6.18.bn2.weight\", \"backbone.6.18.bn2.bias\", \"backbone.6.18.bn2.running_mean\", \"backbone.6.18.bn2.running_var\", \"backbone.6.18.bn2.num_batches_tracked\", \"backbone.6.18.conv3.weight\", \"backbone.6.18.bn3.weight\", \"backbone.6.18.bn3.bias\", \"backbone.6.18.bn3.running_mean\", \"backbone.6.18.bn3.running_var\", \"backbone.6.18.bn3.num_batches_tracked\", \"backbone.6.19.conv1.weight\", \"backbone.6.19.bn1.weight\", \"backbone.6.19.bn1.bias\", \"backbone.6.19.bn1.running_mean\", \"backbone.6.19.bn1.running_var\", \"backbone.6.19.bn1.num_batches_tracked\", \"backbone.6.19.conv2.weight\", \"backbone.6.19.bn2.weight\", \"backbone.6.19.bn2.bias\", \"backbone.6.19.bn2.running_mean\", \"backbone.6.19.bn2.running_var\", \"backbone.6.19.bn2.num_batches_tracked\", \"backbone.6.19.conv3.weight\", \"backbone.6.19.bn3.weight\", \"backbone.6.19.bn3.bias\", \"backbone.6.19.bn3.running_mean\", \"backbone.6.19.bn3.running_var\", \"backbone.6.19.bn3.num_batches_tracked\", \"backbone.6.20.conv1.weight\", \"backbone.6.20.bn1.weight\", \"backbone.6.20.bn1.bias\", \"backbone.6.20.bn1.running_mean\", \"backbone.6.20.bn1.running_var\", \"backbone.6.20.bn1.num_batches_tracked\", \"backbone.6.20.conv2.weight\", \"backbone.6.20.bn2.weight\", \"backbone.6.20.bn2.bias\", \"backbone.6.20.bn2.running_mean\", \"backbone.6.20.bn2.running_var\", \"backbone.6.20.bn2.num_batches_tracked\", \"backbone.6.20.conv3.weight\", \"backbone.6.20.bn3.weight\", \"backbone.6.20.bn3.bias\", \"backbone.6.20.bn3.running_mean\", \"backbone.6.20.bn3.running_var\", \"backbone.6.20.bn3.num_batches_tracked\", \"backbone.6.21.conv1.weight\", \"backbone.6.21.bn1.weight\", \"backbone.6.21.bn1.bias\", \"backbone.6.21.bn1.running_mean\", \"backbone.6.21.bn1.running_var\", \"backbone.6.21.bn1.num_batches_tracked\", \"backbone.6.21.conv2.weight\", \"backbone.6.21.bn2.weight\", \"backbone.6.21.bn2.bias\", \"backbone.6.21.bn2.running_mean\", \"backbone.6.21.bn2.running_var\", \"backbone.6.21.bn2.num_batches_tracked\", \"backbone.6.21.conv3.weight\", \"backbone.6.21.bn3.weight\", \"backbone.6.21.bn3.bias\", \"backbone.6.21.bn3.running_mean\", \"backbone.6.21.bn3.running_var\", \"backbone.6.21.bn3.num_batches_tracked\", \"backbone.6.22.conv1.weight\", \"backbone.6.22.bn1.weight\", \"backbone.6.22.bn1.bias\", \"backbone.6.22.bn1.running_mean\", \"backbone.6.22.bn1.running_var\", \"backbone.6.22.bn1.num_batches_tracked\", \"backbone.6.22.conv2.weight\", \"backbone.6.22.bn2.weight\", \"backbone.6.22.bn2.bias\", \"backbone.6.22.bn2.running_mean\", \"backbone.6.22.bn2.running_var\", \"backbone.6.22.bn2.num_batches_tracked\", \"backbone.6.22.conv3.weight\", \"backbone.6.22.bn3.weight\", \"backbone.6.22.bn3.bias\", \"backbone.6.22.bn3.running_mean\", \"backbone.6.22.bn3.running_var\", \"backbone.6.22.bn3.num_batches_tracked\", \"backbone.6.23.conv1.weight\", \"backbone.6.23.bn1.weight\", \"backbone.6.23.bn1.bias\", \"backbone.6.23.bn1.running_mean\", \"backbone.6.23.bn1.running_var\", \"backbone.6.23.bn1.num_batches_tracked\", \"backbone.6.23.conv2.weight\", \"backbone.6.23.bn2.weight\", \"backbone.6.23.bn2.bias\", \"backbone.6.23.bn2.running_mean\", \"backbone.6.23.bn2.running_var\", \"backbone.6.23.bn2.num_batches_tracked\", \"backbone.6.23.conv3.weight\", \"backbone.6.23.bn3.weight\", \"backbone.6.23.bn3.bias\", \"backbone.6.23.bn3.running_mean\", \"backbone.6.23.bn3.running_var\", \"backbone.6.23.bn3.num_batches_tracked\", \"backbone.6.24.conv1.weight\", \"backbone.6.24.bn1.weight\", \"backbone.6.24.bn1.bias\", \"backbone.6.24.bn1.running_mean\", \"backbone.6.24.bn1.running_var\", \"backbone.6.24.bn1.num_batches_tracked\", \"backbone.6.24.conv2.weight\", \"backbone.6.24.bn2.weight\", \"backbone.6.24.bn2.bias\", \"backbone.6.24.bn2.running_mean\", \"backbone.6.24.bn2.running_var\", \"backbone.6.24.bn2.num_batches_tracked\", \"backbone.6.24.conv3.weight\", \"backbone.6.24.bn3.weight\", \"backbone.6.24.bn3.bias\", \"backbone.6.24.bn3.running_mean\", \"backbone.6.24.bn3.running_var\", \"backbone.6.24.bn3.num_batches_tracked\", \"backbone.6.25.conv1.weight\", \"backbone.6.25.bn1.weight\", \"backbone.6.25.bn1.bias\", \"backbone.6.25.bn1.running_mean\", \"backbone.6.25.bn1.running_var\", \"backbone.6.25.bn1.num_batches_tracked\", \"backbone.6.25.conv2.weight\", \"backbone.6.25.bn2.weight\", \"backbone.6.25.bn2.bias\", \"backbone.6.25.bn2.running_mean\", \"backbone.6.25.bn2.running_var\", \"backbone.6.25.bn2.num_batches_tracked\", \"backbone.6.25.conv3.weight\", \"backbone.6.25.bn3.weight\", \"backbone.6.25.bn3.bias\", \"backbone.6.25.bn3.running_mean\", \"backbone.6.25.bn3.running_var\", \"backbone.6.25.bn3.num_batches_tracked\", \"backbone.6.26.conv1.weight\", \"backbone.6.26.bn1.weight\", \"backbone.6.26.bn1.bias\", \"backbone.6.26.bn1.running_mean\", \"backbone.6.26.bn1.running_var\", \"backbone.6.26.bn1.num_batches_tracked\", \"backbone.6.26.conv2.weight\", \"backbone.6.26.bn2.weight\", \"backbone.6.26.bn2.bias\", \"backbone.6.26.bn2.running_mean\", \"backbone.6.26.bn2.running_var\", \"backbone.6.26.bn2.num_batches_tracked\", \"backbone.6.26.conv3.weight\", \"backbone.6.26.bn3.weight\", \"backbone.6.26.bn3.bias\", \"backbone.6.26.bn3.running_mean\", \"backbone.6.26.bn3.running_var\", \"backbone.6.26.bn3.num_batches_tracked\", \"backbone.6.27.conv1.weight\", \"backbone.6.27.bn1.weight\", \"backbone.6.27.bn1.bias\", \"backbone.6.27.bn1.running_mean\", \"backbone.6.27.bn1.running_var\", \"backbone.6.27.bn1.num_batches_tracked\", \"backbone.6.27.conv2.weight\", \"backbone.6.27.bn2.weight\", \"backbone.6.27.bn2.bias\", \"backbone.6.27.bn2.running_mean\", \"backbone.6.27.bn2.running_var\", \"backbone.6.27.bn2.num_batches_tracked\", \"backbone.6.27.conv3.weight\", \"backbone.6.27.bn3.weight\", \"backbone.6.27.bn3.bias\", \"backbone.6.27.bn3.running_mean\", \"backbone.6.27.bn3.running_var\", \"backbone.6.27.bn3.num_batches_tracked\", \"backbone.6.28.conv1.weight\", \"backbone.6.28.bn1.weight\", \"backbone.6.28.bn1.bias\", \"backbone.6.28.bn1.running_mean\", \"backbone.6.28.bn1.running_var\", \"backbone.6.28.bn1.num_batches_tracked\", \"backbone.6.28.conv2.weight\", \"backbone.6.28.bn2.weight\", \"backbone.6.28.bn2.bias\", \"backbone.6.28.bn2.running_mean\", \"backbone.6.28.bn2.running_var\", \"backbone.6.28.bn2.num_batches_tracked\", \"backbone.6.28.conv3.weight\", \"backbone.6.28.bn3.weight\", \"backbone.6.28.bn3.bias\", \"backbone.6.28.bn3.running_mean\", \"backbone.6.28.bn3.running_var\", \"backbone.6.28.bn3.num_batches_tracked\", \"backbone.6.29.conv1.weight\", \"backbone.6.29.bn1.weight\", \"backbone.6.29.bn1.bias\", \"backbone.6.29.bn1.running_mean\", \"backbone.6.29.bn1.running_var\", \"backbone.6.29.bn1.num_batches_tracked\", \"backbone.6.29.conv2.weight\", \"backbone.6.29.bn2.weight\", \"backbone.6.29.bn2.bias\", \"backbone.6.29.bn2.running_mean\", \"backbone.6.29.bn2.running_var\", \"backbone.6.29.bn2.num_batches_tracked\", \"backbone.6.29.conv3.weight\", \"backbone.6.29.bn3.weight\", \"backbone.6.29.bn3.bias\", \"backbone.6.29.bn3.running_mean\", \"backbone.6.29.bn3.running_var\", \"backbone.6.29.bn3.num_batches_tracked\", \"backbone.6.30.conv1.weight\", \"backbone.6.30.bn1.weight\", \"backbone.6.30.bn1.bias\", \"backbone.6.30.bn1.running_mean\", \"backbone.6.30.bn1.running_var\", \"backbone.6.30.bn1.num_batches_tracked\", \"backbone.6.30.conv2.weight\", \"backbone.6.30.bn2.weight\", \"backbone.6.30.bn2.bias\", \"backbone.6.30.bn2.running_mean\", \"backbone.6.30.bn2.running_var\", \"backbone.6.30.bn2.num_batches_tracked\", \"backbone.6.30.conv3.weight\", \"backbone.6.30.bn3.weight\", \"backbone.6.30.bn3.bias\", \"backbone.6.30.bn3.running_mean\", \"backbone.6.30.bn3.running_var\", \"backbone.6.30.bn3.num_batches_tracked\", \"backbone.6.31.conv1.weight\", \"backbone.6.31.bn1.weight\", \"backbone.6.31.bn1.bias\", \"backbone.6.31.bn1.running_mean\", \"backbone.6.31.bn1.running_var\", \"backbone.6.31.bn1.num_batches_tracked\", \"backbone.6.31.conv2.weight\", \"backbone.6.31.bn2.weight\", \"backbone.6.31.bn2.bias\", \"backbone.6.31.bn2.running_mean\", \"backbone.6.31.bn2.running_var\", \"backbone.6.31.bn2.num_batches_tracked\", \"backbone.6.31.conv3.weight\", \"backbone.6.31.bn3.weight\", \"backbone.6.31.bn3.bias\", \"backbone.6.31.bn3.running_mean\", \"backbone.6.31.bn3.running_var\", \"backbone.6.31.bn3.num_batches_tracked\", \"backbone.6.32.conv1.weight\", \"backbone.6.32.bn1.weight\", \"backbone.6.32.bn1.bias\", \"backbone.6.32.bn1.running_mean\", \"backbone.6.32.bn1.running_var\", \"backbone.6.32.bn1.num_batches_tracked\", \"backbone.6.32.conv2.weight\", \"backbone.6.32.bn2.weight\", \"backbone.6.32.bn2.bias\", \"backbone.6.32.bn2.running_mean\", \"backbone.6.32.bn2.running_var\", \"backbone.6.32.bn2.num_batches_tracked\", \"backbone.6.32.conv3.weight\", \"backbone.6.32.bn3.weight\", \"backbone.6.32.bn3.bias\", \"backbone.6.32.bn3.running_mean\", \"backbone.6.32.bn3.running_var\", \"backbone.6.32.bn3.num_batches_tracked\", \"backbone.6.33.conv1.weight\", \"backbone.6.33.bn1.weight\", \"backbone.6.33.bn1.bias\", \"backbone.6.33.bn1.running_mean\", \"backbone.6.33.bn1.running_var\", \"backbone.6.33.bn1.num_batches_tracked\", \"backbone.6.33.conv2.weight\", \"backbone.6.33.bn2.weight\", \"backbone.6.33.bn2.bias\", \"backbone.6.33.bn2.running_mean\", \"backbone.6.33.bn2.running_var\", \"backbone.6.33.bn2.num_batches_tracked\", \"backbone.6.33.conv3.weight\", \"backbone.6.33.bn3.weight\", \"backbone.6.33.bn3.bias\", \"backbone.6.33.bn3.running_mean\", \"backbone.6.33.bn3.running_var\", \"backbone.6.33.bn3.num_batches_tracked\", \"backbone.6.34.conv1.weight\", \"backbone.6.34.bn1.weight\", \"backbone.6.34.bn1.bias\", \"backbone.6.34.bn1.running_mean\", \"backbone.6.34.bn1.running_var\", \"backbone.6.34.bn1.num_batches_tracked\", \"backbone.6.34.conv2.weight\", \"backbone.6.34.bn2.weight\", \"backbone.6.34.bn2.bias\", \"backbone.6.34.bn2.running_mean\", \"backbone.6.34.bn2.running_var\", \"backbone.6.34.bn2.num_batches_tracked\", \"backbone.6.34.conv3.weight\", \"backbone.6.34.bn3.weight\", \"backbone.6.34.bn3.bias\", \"backbone.6.34.bn3.running_mean\", \"backbone.6.34.bn3.running_var\", \"backbone.6.34.bn3.num_batches_tracked\", \"backbone.6.35.conv1.weight\", \"backbone.6.35.bn1.weight\", \"backbone.6.35.bn1.bias\", \"backbone.6.35.bn1.running_mean\", \"backbone.6.35.bn1.running_var\", \"backbone.6.35.bn1.num_batches_tracked\", \"backbone.6.35.conv2.weight\", \"backbone.6.35.bn2.weight\", \"backbone.6.35.bn2.bias\", \"backbone.6.35.bn2.running_mean\", \"backbone.6.35.bn2.running_var\", \"backbone.6.35.bn2.num_batches_tracked\", \"backbone.6.35.conv3.weight\", \"backbone.6.35.bn3.weight\", \"backbone.6.35.bn3.bias\", \"backbone.6.35.bn3.running_mean\", \"backbone.6.35.bn3.running_var\", \"backbone.6.35.bn3.num_batches_tracked\". \n\tsize mismatch for rpn.head.cls_logits.weight: copying a param with shape torch.Size([15, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([9, 2048, 1, 1]).\n\tsize mismatch for rpn.head.cls_logits.bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([9]).\n\tsize mismatch for rpn.head.bbox_pred.weight: copying a param with shape torch.Size([60, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([36, 2048, 1, 1]).\n\tsize mismatch for rpn.head.bbox_pred.bias: copying a param with shape torch.Size([60]) from checkpoint, the shape in current model is torch.Size([36])."
     ]
    }
   ],
   "source": [
    "#load weights onto model (!only works if params specified above match the one used in the trained version that is loaded)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/wandermarijnissen/repos/Wander-python/inference2.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wandermarijnissen/repos/Wander-python/inference2.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x, x_name \u001b[39m=\u001b[39m sample\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wandermarijnissen/repos/Wander-python/inference2.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wandermarijnissen/repos/Wander-python/inference2.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wandermarijnissen/repos/Wander-python/inference2.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     pred \u001b[39m=\u001b[39m {key: value\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m pred[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wandermarijnissen/repos/Wander-python/inference2.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     name \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(x_name[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py:93\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     88\u001b[0m             degen_bb: List[\u001b[39mfloat\u001b[39m] \u001b[39m=\u001b[39m boxes[bb_idx]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     89\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll bounding boxes should have positive height and width.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39m Found invalid box \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for target at index \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m                              \u001b[39m.\u001b[39mformat(degen_bb, target_idx))\n\u001b[0;32m---> 93\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(images\u001b[39m.\u001b[39;49mtensors)\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(features, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m     95\u001b[0m     features \u001b[39m=\u001b[39m OrderedDict([(\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m, features)])\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torchvision/models/resnet.py:128\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    125\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[1;32m    126\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m--> 128\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(out)\n\u001b[1;32m    129\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[1;32m    130\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/my_venvs/project1_venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    440\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    441\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 442\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    443\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# inference (cpu) --> makes the predictions and saves then in predictions_path as specified in params\n",
    "model.eval()\n",
    "for sample in dataloader_prediction:\n",
    "    x, x_name = sample\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        pred = {key: value.numpy() for key, value in pred[0].items()}\n",
    "        name = pathlib.Path(x_name[0])\n",
    "        save_dir = pathlib.Path(os.getcwd()) / params['PREDICTIONS_PATH']\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pred_list = {key: value.tolist() for key, value in pred.items()}  # numpy arrays are not serializable -> .tolist()\n",
    "        save_json(pred_list, path=save_dir / name.with_suffix('.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction files (json) & sort them\n",
    "predictions = get_filenames_of_path(pathlib.Path(os.getcwd()) / params['PREDICTIONS_PATH'])\n",
    "predictions.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set IoU threshold & score threshold\n",
    "iou_threshold = 0.25\n",
    "score_threshold = 0.5\n",
    "\n",
    "# set transformations applied to dataset with predictions (can experiment with nms and score threshold)\n",
    "transforms_prediction = ComposeDouble([\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01),\n",
    "    FunctionWrapperDouble(apply_nms, input=False, target=True, iou_threshold=iou_threshold),\n",
    "    FunctionWrapperDouble(apply_score_threshold, input=False, target=True, score_threshold=score_threshold)\n",
    "])\n",
    "\n",
    "#create dataset with predictions\n",
    "dataset_prediction = ObjectDetectionDataSet(inputs=inputs,\n",
    "                                            targets=predictions,\n",
    "                                            transform=transforms_prediction,\n",
    "                                            use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "color_mapping = {\n",
    "    1: 'red',\n",
    "}\n",
    "\n",
    "# visualize predictions\n",
    "datasetviewer_prediction = DatasetViewer(dataset_prediction, color_mapping)\n",
    "datasetviewer_prediction.napari()\n",
    "# add text properties gui\n",
    "datasetviewer_prediction.gui_text_properties(datasetviewer_prediction.shape_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1_venv",
   "language": "python",
   "name": "project1_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "458636e651591ca51347e3e0712a00eab8b2b9edaf77c0e1598bf494c6770d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
